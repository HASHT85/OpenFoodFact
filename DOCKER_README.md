# ğŸ³ Docker - OpenFoodFacts ETL

Configuration Docker simplifiÃ©e pour le projet ETL.

## ğŸ“¦ Fichiers Docker

### Configuration
- `Dockerfile` - Image Python 3.10 + PySpark + Java 17 + MySQL
- `docker-compose.yml` - 3 services (MySQL, ETL, Jupyter)
- `.dockerignore` - Optimisation du build
- `entrypoint.sh` - Script d'initialisation
- `.env.example` - Template de configuration

### Automatisation
- `Makefile` - 30+ commandes simplifiÃ©es
- `scripts/docker_init.sh` - Setup automatique

## ğŸš€ Utilisation

### Installation (3 Ã©tapes)

```bash
# 1. Setup
bash scripts/docker_init.sh

# 2. DÃ©marrer
make up

# 3. ExÃ©cuter ETL
make etl-test
```

### Commandes Principales

```bash
make help            # Liste toutes les commandes

# Services
make up              # DÃ©marrer
make down            # ArrÃªter
make logs            # Logs
make ps              # Statut

# ETL
make etl-test        # Test avec donnÃ©es Ã©chantillon
make etl-full        # Pipeline complet
make etl-skip        # RÃ©utiliser Bronze existant

# DÃ©veloppement
make shell           # Shell ETL
make mysql-shell     # Console MySQL
make jupyter         # Jupyter Lab
make test            # Tests
```

## ğŸ“‹ Services

### MySQL
- Port: 3306
- Database: off_datamart
- User: root
- Password: password (changeable dans .env)

### ETL (PySpark)
- Python 3.10
- PySpark 3.5
- Java 17
- Volumes montÃ©s pour hot-reload

### Jupyter (optionnel)
- Port: 8888
- AccÃ¨s: http://localhost:8888
- DÃ©marrer: `make jupyter`

## ğŸ”§ Configuration

CrÃ©er `.env` depuis le template:

```bash
cp .env.example .env
```

Personnaliser:

```bash
# Base de donnÃ©es
DB_PORT=3306
DB_NAME=off_datamart
DB_ROOT_PASSWORD=password

# Spark
SPARK_DRIVER_MEMORY=2g
SPARK_EXECUTOR_MEMORY=2g

# Jupyter
JUPYTER_PORT=8888
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Docker Compose Stack          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ MySQL  â”‚  â”‚  ETL   â”‚  â”‚Jupyterâ”‚â”‚
â”‚  â”‚ :3306  â”‚â—„â”€â”¤PySpark â”‚  â”‚ :8888 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         off_network                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚            â”‚           â”‚
  [mysql_data] [./data/]  [jupyter_data]
```

## ğŸ§ª Workflow

### DÃ©veloppement

```bash
# 1. DÃ©marrer
make up

# 2. Modifier le code localement
# Les fichiers etl/ sont montÃ©s en volume

# 3. Tester immÃ©diatement
make test

# 4. ExÃ©cuter ETL
make etl-test
```

### Debug

```bash
# Shell interactif
make shell

# Logs en temps rÃ©el
make logs-etl

# VÃ©rifier base de donnÃ©es
make mysql-shell
```

## ğŸ†˜ DÃ©pannage

### Services ne dÃ©marrent pas

```bash
make build
make up
make logs
```

### Erreur MySQL

```bash
make down
docker volume rm off_mysql_data
make up
```

### Erreur mÃ©moire Spark

```bash
echo "SPARK_DRIVER_MEMORY=4g" >> .env
make restart
```

### Port occupÃ©

```bash
# Changer le port dans .env
echo "DB_PORT=3307" >> .env
make down && make up
```

## ğŸ“Š Avantages

âœ… **Installation simplifiÃ©e** - 3 commandes vs 20+
âœ… **Reproductible** - Fonctionne sur Win/Linux/Mac
âœ… **IsolÃ©** - Pas de conflit avec systÃ¨me
âœ… **Hot-reload** - Modifications instantanÃ©es
âœ… **Complet** - MySQL + Spark + Jupyter

## ğŸ“š Documentation

- **QUICKSTART.md** - Guide de dÃ©marrage rapide
- **README.md** - Vue d'ensemble du projet
- **docs/architecture.md** - Architecture ETL
- **docs/CAHIER_DE_QUALITE.md** - QualitÃ© des donnÃ©es

## ğŸ¯ Pour le Rendu

```bash
# Pipeline complet
make build && make up && make etl-test

# GÃ©nÃ©rer livrables
make logs-etl > logs.txt
cat data/quality_reports/*.json > qualite.json

# VÃ©rifier rÃ©sultats
make mysql-shell
```

---

**Installation en 3 commandes. ExÃ©cution en 2 minutes.** ğŸš€
