# ðŸ§ª Guide de Test - OpenFoodFacts ETL

Guide complet pour tester votre projet dockerisÃ©.

## âœ… Checklist de Test

### Phase 1: PrÃ©requis (2 min)

```bash
# 1. VÃ©rifier Docker
docker --version
docker-compose --version

# 2. VÃ©rifier que Docker tourne
docker ps

# 3. Se placer dans le projet
cd C:\Projet\OFF\OpenFoodFact
```

**RÃ©sultat attendu:**
- Docker version 20.10+
- Docker Compose version 1.29+
- Commande `docker ps` fonctionne

---

### Phase 2: Configuration (1 min)

```bash
# 1. CrÃ©er le fichier .env
cp .env.example .env

# 2. VÃ©rifier le contenu
cat .env

# 3. CrÃ©er les dossiers nÃ©cessaires
mkdir -p data/bronze data/silver data/gold data/quality_reports
mkdir -p logs backups
```

**RÃ©sultat attendu:**
- Fichier `.env` crÃ©Ã© avec les variables de config
- Dossiers `data/`, `logs/`, `backups/` crÃ©Ã©s

---

### Phase 3: Build des Images (5-10 min)

```bash
# Construction des images Docker
docker-compose build

# VÃ©rifier les images crÃ©Ã©es
docker images | grep off
```

**RÃ©sultat attendu:**
```
off_etl        latest    xxx    xxx ago    1.2GB
```

**Si erreur de build:**
```bash
# Rebuild sans cache
docker-compose build --no-cache

# Voir les logs dÃ©taillÃ©s
docker-compose build --progress=plain
```

---

### Phase 4: DÃ©marrage des Services (1 min)

```bash
# DÃ©marrer MySQL + ETL
docker-compose up -d mysql etl

# Attendre 30 secondes que MySQL dÃ©marre
# Puis vÃ©rifier l'Ã©tat
docker-compose ps
```

**RÃ©sultat attendu:**
```
NAME        IMAGE       STATUS              PORTS
off_mysql   mysql:8.0   Up 30 seconds      0.0.0.0:3306->3306/tcp
off_etl     ...         Up 30 seconds
```

**Si services ne dÃ©marrent pas:**
```bash
# Voir les logs
docker-compose logs mysql
docker-compose logs etl
```

---

### Phase 5: Test de Connexion (1 min)

```bash
# Test 1: MySQL est accessible
docker-compose exec mysql mysqladmin ping -h localhost -u root -ppassword

# Test 2: Base de donnÃ©es existe
docker-compose exec mysql mysql -u root -ppassword -e "SHOW DATABASES;"

# Test 3: Tables crÃ©Ã©es
docker-compose exec mysql mysql -u root -ppassword off_datamart -e "SHOW TABLES;"
```

**RÃ©sultat attendu:**
```
mysqld is alive

DATABASES:
off_datamart

TABLES:
dim_brand
dim_category
dim_country
dim_product
dim_time
fact_nutrition_snapshot
```

---

### Phase 6: Test ETL avec DonnÃ©es Ã‰chantillon (2-3 min)

```bash
# ExÃ©cuter le pipeline complet avec donnÃ©es de test
docker-compose exec etl python -m etl.main tests/sample_data.jsonl

# Ou avec Make (si disponible)
make etl-test
```

**RÃ©sultat attendu:**
```
================================================================================
STARTING FULL ETL PIPELINE
================================================================================
Start time: 2024-01-XX XX:XX:XX
Input path: tests/sample_data.jsonl
================================================================================

[1/6] Running Bronze Ingestion...
âœ“ Ingested X records

[2/6] Running Silver Conformation...
âœ“ Processed X records

[3/6] Loading Dimensions...
âœ“ Loaded dimensions

[4/6] Loading Products (SCD2)...
âœ“ Loaded X products

[5/6] Loading Fact Table...
âœ“ Loaded X facts

[6/6] Generating Quality Report...
âœ“ Report generated

================================================================================
ETL PIPELINE COMPLETED SUCCESSFULLY
================================================================================
Duration: XX.XX seconds
================================================================================
```

**Si erreur:**
```bash
# Voir les logs dÃ©taillÃ©s
docker-compose logs etl

# VÃ©rifier la connexion DB
docker-compose exec etl python -c "from etl.settings import DB_CONFIG; print(DB_CONFIG)"
```

---

### Phase 7: VÃ©rification des RÃ©sultats (2 min)

```bash
# 1. Ouvrir la console MySQL
docker-compose exec mysql mysql -u root -ppassword off_datamart
```

```sql
-- Dans MySQL, exÃ©cuter ces requÃªtes:

-- Compter les produits
SELECT COUNT(*) as total_products FROM dim_product WHERE is_current = 1;

-- Compter les faits
SELECT COUNT(*) as total_facts FROM fact_nutrition_snapshot;

-- Voir la distribution Nutri-Score
SELECT
    nutriscore_grade,
    COUNT(*) as count
FROM fact_nutrition_snapshot
GROUP BY nutriscore_grade
ORDER BY nutriscore_grade;

-- Top 5 marques
SELECT
    b.brand_name,
    COUNT(*) as product_count
FROM dim_brand b
JOIN dim_product p ON b.brand_sk = p.brand_sk
WHERE p.is_current = 1
GROUP BY b.brand_name
ORDER BY product_count DESC
LIMIT 5;

-- Sortir de MySQL
exit
```

**RÃ©sultat attendu:**
- Plusieurs produits dans `dim_product`
- DonnÃ©es dans `fact_nutrition_snapshot`
- Distribution des Nutri-Scores (a, b, c, d, e)
- Liste des marques

---

### Phase 8: VÃ©rifier le Rapport QualitÃ© (1 min)

```bash
# Voir le rapport qualitÃ© gÃ©nÃ©rÃ©
cat data/quality_reports/quality_report_*.json

# Ou avec formatage
cat data/quality_reports/quality_report_*.json | python -m json.tool
```

**RÃ©sultat attendu:**
```json
{
  "execution_timestamp": "2024-01-XX...",
  "total_records": XX,
  "completeness": {
    "average_score": 0.XX,
    "distribution": {...}
  },
  "anomalies": {
    "out_of_bounds": XX,
    "missing_required": XX
  },
  "alerts": [...]
}
```

---

### Phase 9: Tests Unitaires (1 min)

```bash
# ExÃ©cuter les tests
docker-compose exec etl pytest tests/test_etl.py -v

# Ou avec Make
make test
```

**RÃ©sultat attendu:**
```
tests/test_etl.py::TestUtils::test_normalize_tag PASSED
tests/test_etl.py::TestUtils::test_convert_sodium_to_salt PASSED
tests/test_etl.py::TestQualityRules::test_check_bounds PASSED
...
======================== X passed in X.XXs ========================
```

---

### Phase 10: Test Jupyter (Optionnel - 1 min)

```bash
# DÃ©marrer Jupyter
docker-compose up -d jupyter

# Attendre 10 secondes
# Ouvrir dans le navigateur
start http://localhost:8888

# Ou sur Linux/Mac
open http://localhost:8888
```

**RÃ©sultat attendu:**
- Jupyter Lab s'ouvre dans le navigateur
- AccÃ¨s au notebook `projet/OpenFoodFacts_ETL_Workshop.ipynb`

---

## ðŸŽ¯ Tests AvancÃ©s (Optionnel)

### Test avec Dataset Complet

```bash
# 1. TÃ©lÃ©charger le dataset (~5GB, ~30 min)
docker-compose exec etl python download_dump.py

# 2. ExÃ©cuter le pipeline complet (~10-30 min selon machine)
docker-compose exec etl python -m etl.main data/openfoodfacts-products.jsonl

# 3. VÃ©rifier les rÃ©sultats
docker-compose exec mysql mysql -u root -ppassword off_datamart -e "
SELECT COUNT(*) as total FROM fact_nutrition_snapshot;
"
```

### Test IncrÃ©mental

```bash
# 1. Premier run
docker-compose exec etl python -m etl.main tests/sample_data.jsonl

# 2. DeuxiÃ¨me run (devrait dÃ©tecter les doublons)
docker-compose exec etl python -m etl.main tests/sample_data.jsonl

# 3. Run avec skip ingestion (rÃ©utiliser Bronze)
docker-compose exec etl python -m etl.main --skip-ingest
```

---

## ðŸ†˜ Troubleshooting

### ProblÃ¨me: Port 3306 dÃ©jÃ  utilisÃ©

```bash
# Solution 1: ArrÃªter le MySQL local
# Windows: Services â†’ MySQL â†’ Stop
# Linux: sudo service mysql stop

# Solution 2: Changer le port
echo "DB_PORT=3307" >> .env
docker-compose down
docker-compose up -d
```

### ProblÃ¨me: Erreur mÃ©moire Spark

```bash
# Augmenter la mÃ©moire
echo "SPARK_DRIVER_MEMORY=4g" >> .env
docker-compose restart etl
```

### ProblÃ¨me: Erreur MySQL "Access Denied"

```bash
# VÃ©rifier les credentials
docker-compose exec etl env | grep DB_

# RÃ©initialiser MySQL
docker-compose down
docker volume rm off_mysql_data
docker-compose up -d mysql
# Attendre 30 secondes
```

### ProblÃ¨me: Conteneur crashe au dÃ©marrage

```bash
# Voir les logs
docker-compose logs --tail=50 etl
docker-compose logs --tail=50 mysql

# Reconstruire l'image
docker-compose build --no-cache etl
docker-compose up -d
```

---

## ðŸ“Š Checklist Finale

Avant de considÃ©rer le projet validÃ©, vÃ©rifier:

- [ ] Docker et Docker Compose installÃ©s
- [ ] Images Docker buildÃ©es sans erreur
- [ ] Services MySQL et ETL dÃ©marrent
- [ ] Connexion MySQL fonctionne
- [ ] Tables crÃ©Ã©es dans la base
- [ ] ETL s'exÃ©cute sans erreur
- [ ] DonnÃ©es chargÃ©es dans MySQL
- [ ] Rapport qualitÃ© gÃ©nÃ©rÃ©
- [ ] Tests unitaires passent
- [ ] Jupyter accessible (optionnel)

---

## ðŸŽ“ Pour le Rendu

```bash
# 1. DÃ©monstration complÃ¨te
docker-compose build
docker-compose up -d
docker-compose exec etl python -m etl.main tests/sample_data.jsonl

# 2. Capturer les rÃ©sultats
docker-compose logs etl > rendu/logs_execution.txt
cat data/quality_reports/quality_report_*.json > rendu/qualite.json
docker-compose exec mysql mysql -u root -ppassword off_datamart < sql/analysis_queries.sql > rendu/sql_results.txt

# 3. Screenshots
# - ExÃ©cution du pipeline
# - RÃ©sultats dans MySQL
# - Rapport qualitÃ©
```

---

## ðŸ“ž Aide

**Si blocage:**
1. Consulter les logs: `docker-compose logs`
2. VÃ©rifier QUICKSTART.md
3. VÃ©rifier DOCKER_README.md
4. Reconstruire: `docker-compose build --no-cache`

**Tout rÃ©initialiser:**
```bash
docker-compose down -v
docker system prune -a
rm -rf data/bronze data/silver data/gold
# Puis refaire: docker-compose build && docker-compose up -d
```

---

**Temps total de test: ~15-20 minutes**
**Temps avec dataset complet: ~1-2 heures**
